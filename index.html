
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-110862391-1');
  </script>

  <title>Maximilian Sieb</title>
  
  <meta name="author" content="Maximilian Sieb">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link rel="icon" type="image/png" href="img/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
          <name>Maximilian Sieb</name>
        <p>I am currently working as an AI Lead at an early-stage start-up in San Francisco. Before that, I was working on computer vision and reinforcement & imitation learning for robot manipulation at <a href="https://covariant.ai/">Covariant.ai</a>. 
        </p>
          I graduated from the MSR program at the Robotics Institute at Carnegie Mellon University, where I was glad to have been co-advised by <a href="https://www.cs.cmu.edu/~katef/"> Katerina Fragkiadaki</a> & <a href="https://www.ri.cmu.edu/ri-faculty/oliver-kroemer/">Oliver Kroemer</a>.
          <br>I also got a Bachelors in Mechanical Engineering and a Masters in Computational Engineering from the <a href="https://www.tu-darmstadt.de/"> Technical University Darmstadt</a>. </p> 
              <p style="text-align:center">
          <a href="https://scholar.google.com/citations?user=RJ_c4xkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://twitter.com/msieb1">Twitter</a> &nbsp/&nbsp
          <a href="https://github.com/msieb1">GitHub</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/maximilian-sieb/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              
    <a href="assets/profile_pic.jpg">
        <img src="assets/profile_pic.jpg" width="250px"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/bbox3d.gif" alt="sosmc" width="160"></td>
            <td width="75%" valign="top">
            <p>
            <p>
              <a href="https://bbox.yuxuanliu.com/">
              <papertitle>Autoregressive Uncertainty Modeling for 3D Bounding Box Prediction</papertitle>
              </a>
              <br>
              <a href="https://yuxuanliu.com/">YuXuan Liu</a>, 
              <a href="https://nikhilmishra000.github.io/">Nikhil Mishra</a>,
              <strong>Maximilian Sieb</strong>, 
              <a href="https://ieeexplore.ieee.org/author/37086010086">Yide Shentu</a>,
              <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>
              <a href="https://peterchen.us/">Xi Chen</a><br>
              <em>ECCV, 2022</em><br>
              <a href="https://arxiv.org/abs/2210.07424">paper</a>
              |
              <a href="https://bbox.yuxuanliu.com/">project page</a>
              
            </p>
            <p>We propose methods for leveraging autoregressive models to make high confidence 3D bounding box predictions predictions, achieving strong results on SUN-RGBD, Scannet, KITTI, and our new dataset, COB-3D. We release this simulated dataset which highlights new types of ambiguity that arise in real-world robotics applications, where 3D bounding box prediction has largely been underexplored. </p>
            </p>
            </td>
          </tr>
    
        
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/emblang.gif" alt="sosmc" width="160"></td>
            <td width="75%" valign="top">
            <p>
            <p>
              <a href="https://mihirp1998.github.io/project_pages/emblang/">
              <papertitle>Embodied Language Grounding with 3D Visual Feature Representations</papertitle>
              </a>
              <br>
              <a href="https://mihirp1998.github.io/">Mihir Prabhudesai*</a>, 
              <a href="https://sfish0101.bitbucket.io/">Hsiao-Yu Fish Tung*</a>, 
              <a href="https://stillbreeze.github.io/about/">Syed Ashar Javed*</a>,
              <strong>Maximilian Sieb</strong>, 
              <a href="https://www.cs.cmu.edu/~aharley/">Adam W. Harley</a>,
              <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a><br>
              <em>CVPR, 2020</em><br>
              <a href="https://arxiv.org/abs/1910.01210">paper</a>
              |
              <a href="https://mihirp1998.github.io/project_pages/emblang/">project page</a>
              
            </p>
            <p>We introduce a computational model of simulation semantics that associate language utterances to 3D visual abstractions of the scene they describe. We encode the visual abstractions via 3-dimensional visual feature maps that we obtain via view prediction from different RGB images of the scene in a self-supervised manner.</p>
            </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/gvi.png" alt="sosmc" width="160"></td>
            <td width="75%" valign="top">
            <p>
            <p>
              <a href="https://msieb1.github.io/visual-entity-graphs/">
              <papertitle>Graph-Structured Visual Imitation</papertitle>
              </a>
              <br>
              <strong>Maximilian Sieb*</strong>, 
              <a href="https://www.ri.cmu.edu/ri-people/xian-zhou/">Zhou Xian*</a>, 
              <a href="https://acmilab.org/people/audrey-huang/">Audrey Huang</a>,
              <a href="https://www.ri.cmu.edu/ri-faculty/oliver-kroemer/">Oliver Kroemer</a>,
              <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a><br>
              <em>CoRL, 2019</em> <font color="red"><strong>(spotlight)</strong></font><br>
              <a href="https://arxiv.org/abs/1907.05518">paper</a>
              |
              <a href="rawnerf/index.html">project page</a>
              |
              <a href="pdf/corl_presentation.pdf">slides</a>

              
            </p>
            <p>We propose a graph-structured state representation for visual imitation learning. We show how we can leverage different visual entities of various granularities to obtain a state representation that can be used for reinforcement learning to learn manipulation skills within a few minutes of real-life policy rollouts.</p>
            </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/data-dream.png" alt="sosmc" width="160"></td>
            <td width="75%" valign="top">
            <p>
            <p>
              <a href="http://www.cs.columbia.edu/~allen/S19/Student_Papers/fragiadaki_object_mask.pdf">
              <papertitle>Data Dreaming for Object Detection: Learning Object-Centric State Representations for Visual Imitation</papertitle>
              </a>
              <br>
              <strong>Maximilian Sieb</strong>, 
              <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a><br>
              <em>International Conference on Humanoid Robots, 2018</em> <font color="red"><strong>(oral)</strong></font><br>
              <a href="http://www.cs.columbia.edu/~allen/S19/Student_Papers/fragiadaki_object_mask.pdf">paper</a>
              |
              <a href="pdf/humanoids_presentation.pdf">slides</a>

              
            </p>
            <p>We show how we can use synthetically generated image data from only a few background-subtracted ground-truth images to build instance-specific object detectors robust to partial occlusions. Further, we demonstrate how we can use these detectors to imitate human demonstrations of manipulation tasks in a sample-efficient manner, where the overall imitation learning process takes less than 10 minutes.</p>
            </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/segmentation.png" alt="sosmc" width="160"></td>
            <td width="75%" valign="top">
            <p>
            <p>
              <a href="https://arxiv.org/pdf/1806.06063.pdf">
              <papertitle>Probabilistic Trajectory Segmentation by Means of Hierarchical Dirichlet Process Switching Linear Dynamical Systems</papertitle>
              </a>
              <br>
              <strong>Maximilian Sieb*</strong>, 
              <a href="https://www.pip.tu-darmstadt.de/members_pip/matthias_schultheis.en.jsp">Matthias Schultheis*</a>,
              <a href="https://www.cs.cmu.edu/~katef/">Sebastian Szelag*</a>,
              <a href="https://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a>,
              <a href="https://www.ias.informatik.tu-darmstadt.de/Member/JanPeters">Jan Peters</a><br>
              <em>arXiv, 2018</em> <br>
              <a href="https://arxiv.org/pdf/1806.06063.pdf">paper</a>
              |
              <a hre
              f="https://github.com/msieb1/switching-linear-dynamical-systems">code</a>

              
            </p>
            <p>This work is about inferring dynamical modes of a given trajectory in a non-parametric fashion. Simply said, the algorithm tries to fit multiple linear segments within the trajectory where the number of fitted segments does not have to specified, but is inferred as well by using a non-parametric dirichlet prior.</p>
            </p>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Patents</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/patent_scene_correspondence_2.png" alt="sosmc" width="160"></td>
          <td width="75%" valign="top">
          <p>
          <p>
            <a href="https://patentimages.storage.googleapis.com/fe/60/5f/cec7d7ac8f498e/US20210233258A1.pdf">
            <papertitle>Identifying scene correspondences with neural networks</papertitle>
            </a>
            <br>
            <strong>Maximilian Sieb</strong>, 
            <a href="https://nikhilmishra000.github.io/">Nikhil Mishra</a>,
            <a href="http://rockyduan.com/">Yan Duan</a><br>
            <em>US patent, 2021</em><br>
            <a href="https://patents.google.com/patent/US20210233258A1/en">patent page</a>

            
          </p>
          <p>The idea here is the following: We have a bin from which we wish to pick items. For every pick, we want to avoid picking items which we have failed to pick before. However, because items in the bin might move around between subsequent picks, it is not obvious how to correlate objects across different picks to keep track of the failure count. In this work, we introduce a deep learning based approach to predict correspondences of objects given two scenes.</p>
          </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/traj-opt.png" alt="sosmc" width="160"></td>
          <td width="75%" valign="top">
          <p>
          <p>
            <a href="https://patentimages.storage.googleapis.com/af/49/49/0f05a5826bbfb0/US20210276187A1.pdf">
            <papertitle>Trajectory optimization using neural networks</papertitle>
            </a>
            <br>
            <a href="https://math.berkeley.edu/~hrtang/">Haoran Tang</a>,
            <a href="https://peterchen.us/">Xi Chen</a>,
            <a href="http://rockyduan.com/">Yan Duan</a>,
            <a href="https://nikhilmishra000.github.io/">Nikhil Mishra</a>,
            <a href="https://wuphilipp.github.io/">Philipp Wu</a>,
            <strong>Maximilian Sieb</strong>, 
            <a href="https://ieeexplore.ieee.org/author/37086010086">Yide Shentu</a><br>
            <em>US patent, 2021</em><br>
            <a href="https://patents.google.com/patent/US20210276187A1/en">patent page</a>

            
          </p>
          <p>We use use deep neural networks to quickly predict optimized robotic arm trajectories according to certain constraints in pick & place application for industrial robotics.</p>
          </p>
          </td>
        </tr>
  
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Selected Projects</heading>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    

    
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/master_thesis_vis.png" alt="sosmc" width="160"></td>
        <td width="75%" valign="top">
        <p>
        <p>
          <a href="https://www.ri.cmu.edu/publications/visual-imitation-learning-for-robot-manipulation/">
          <papertitle>Visual Imitation Learning for Robot Manipulation</papertitle>
          </a><br>
          <em>CMU, Master thesis, 2019</em><br>

        </p>
        <p>In my Master thesis I talk about how we can leverage visual imitation learning for robot manipulation. More specifically, I focus on how we can use state-of-the-art computer vision models and reinforcement learning to imitate an expert trajectory from just a single demonstration.</p>
        </p>
        </td>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/aligning.png" alt="sosmc" width="160"></td>
          <td width="75%" valign="top">
          <p>
          <p>
            <a href="pdf/aligning-word-embeddings.pdf">
            <papertitle>Aligning Word Embeddings of Different Languages within a Shared Embedding Space</papertitle>
            </a><br>
            <em>CMU, 10-725 Convex Optimization, 2018</em><br>
  
          </p>
          <p>Learning translations between different languages has drawn a lot of focus recently. In this work, we examined how we can leverage shared embedding spaces of different languages to learn better translations overall.</p>
          </p>
          </td>
  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/bachelor_thesis_vis.png" alt="sosmc" width="160"></td>
            <td width="75%" valign="top">
            <p>
            <p>
              <a href="pdf/aligning-word-embeddings.pdf">
              <papertitle>Design and Analysis of a Ball-Balancing Plate</papertitle>
              </a><br>
              <em>TU Darmstadt/UIUC, Bachelor thesis, 2016</em><br>
    
            </p>
            <p>This project revolves around the design of a ball-balancing plate and the anaylsis & implementation of different control algorithms. The thesis describes the entire design process: The CAD-design of the contraption, the dynamical & mechanical analysis, the control design & analysis, the microcontroller implementation, and experimental verification.</p>
            </p>
            </td>
      </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          Yet another <a href="https://jonbarron.info">Jon Barron</a> website. <br>
          Last updated July 2022.
      </font>
        </p>
        </td>
      </tr>
      </table>
    </td>
    </tr>
  </table>
  </body>
</html>
